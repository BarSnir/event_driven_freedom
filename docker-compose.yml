services:
  db:
    container_name: legacy-mysql
    image: mysql:5.7
    platform: linux/x86_64
    restart: always
    attach: false
    command: --transaction-isolation=READ-COMMITTED --log-bin=binlog --binlog-format=ROW --server-id=1
    environment:
      MYSQL_DATABASE: 'db'
      MYSQL_USER: 'user'
      MYSQL_PASSWORD: 'password'
      MYSQL_ROOT_PASSWORD: 'password'
    ports:
      - '3306:3306'
    expose:
      - '3306'
    volumes:
      - my_db:/var/lib/mysql
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    platform: linux/amd64
    restart: always
    attach: false
    healthcheck:
      test: echo 'ruok' | nc -w 2 localhost 2181 | grep imok
      start_period: 50s
      timeout: 10s
      retries: 5
      interval: 30s
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: -Dzookeeper.4lw.commands.whitelist=ruok
  broker:
    image: confluentinc/cp-kafka:7.5.3
    container_name: broker
    platform: linux/amd64
    attach: false
    restart: always
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 50s
      interval: 20s
      timeout: 10s
      retries: 10
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.3
    container_name: schema-registry
    platform: linux/amd64
    attach: false
    restart: always
    depends_on:
      broker:
        condition: service_healthy
    healthcheck:
      test: curl --output /dev/null --silent --head --fail http://schema-registry:8082/subjects
      start_period: 2m
      interval: 30s
      timeout: 10s
      retries: 10
    ports:
      - "8082:8082"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8082
  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.5.3
    container_name: kafka-connect
    platform: linux/amd64
    attach: false
    restart: always
    depends_on:
      schema-registry:
        condition: service_healthy
    ports:
      - 8083:8083
    healthcheck:
      test: curl http://kafka-connect:8083/ || exit 1
      start_period: 4m
      interval: 30s
      timeout: 10s
      retries: 1
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "broker:29092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8082'
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components'
    command: > 
      bash -c "
      confluent-hub install --no-prompt debezium/debezium-connector-mysql:2.2.1 && \
      confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.0.12 && \
      confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.5.9 && \
      confluent-hub install --no-prompt neo4j/kafka-connect-neo4j:5.0.4 && \
      /etc/confluent/docker/run"
  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.3
    hostname: control-center
    container_name: control-center
    attach: false
    depends_on:
      kafka-connect:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'http://kafka-connect:8083'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8082"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      PORT: 9021
  jobmanager:
    container_name: jobmanager
    platform: linux/arm64/v8
    hostname: jobmanager
    build:
      context: ./images/pyflink
      dockerfile: .Dockerfile
    ports:
      - "8081:8081"
    command: jobmanager
    attach: false
    restart: always
    volumes:
      - ./datasets:/opt/flink/datasets
      - ./flink_checkpoints:/opt/flink/checkpoints
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        jobmanager.memory.process.size: 2500m
        jobstore.max-capacity: 8
        jobstore.type: file
        state.checkpoint-storage: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.checkpoints.num-retained: 3
        execution.checkpointing.interval: 1000
        execution.checkpointing.min-pause: 500
        execution.checkpointing.tolerable-failed-checkpoints: 2 
        execution.checkpointing.timeout: 60000
        execution.checkpointing.unaligned.enabled: true
        execution.checkpointing.externalized-checkpoint-retention: DELETE_ON_CANCELLATION
  taskmanager:
    container_name: taskmanager
    platform: linux/arm64/v8
    attach: false
    restart: always
    build:
      context: ./images/pyflink
      dockerfile: .Dockerfile
    depends_on:
      - jobmanager
    command: taskmanager
    volumes:
      - ./datasets:/opt/flink/datasets
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 8
        parallelism.default: 1
        taskmanager.memory.process.size: 11500m
        taskmanager.memory.flink.size: 10000m
        taskmanager.memory.managed.size: 1500m
        taskmanager.memory.task.heap.size: 1800m
        taskmanager.memory.task.off-heap.size: 1000m
        taskmanager.memory.framework.off-heap.size: 2700m
        taskmanager.memory.framework.heap.size: 1800m
        taskmanager.memory.jvm-metaspace.size: 1200m
    links:
      - db:db
  pyflink-client:
    platform: linux/arm64/v8
    container_name: pyflink-client
    depends_on:
      - control-center
    build:
      context: ./images/pyflink
      dockerfile: .Dockerfile
    command: >
      bash -c  "python ./project/main.py"
    environment:
      - DATABASE=production
      - DB_HOST=db
      - DB_USER=root
      - DB_PASSWORD=password
      - ENV=development
      - DB_CONFIG=/opt/flink/project/configs/database.json
      - PROCESS_CONFIG_PATH=/opt/flink/project/configs/process_config.json
      - DEBEZIUM_CONFIG_FILE_PATH=/opt/flink/project/configs/debezium.json
      - SCRIPTS_PATH_DIR=/opt/flink/project/scripts
      - CONNECT_URL=http://kafka-connect:8083
      - KAFKA_SERVERS=broker:29092
      - ELASTICSEARCH_URL=elasticsearch:9200
      - MINIO_HOST=minio:9000
      - MINIO_USER=bar
      - MINIO_PASSWORD=Strong#Pass#2022
      - SINK_BUCKET=raw-zone
    volumes:
      - ./flink_process:/opt/flink/ops
      - ./jars:/opt/flink/opt
      - ./datasets:/opt/flink/datasets
      - .:/opt/flink/project
      - ./flink_checkpoints:/opt/flink/checkpoints
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
    scale: 1
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    attach: false
    container_name: elasticsearch
    platform: linux/amd64
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - ./elasticsearch_vol:/usr/share/elasticsearch/data
  kibana:
    container_name: kibana
    attach: false
    image: docker.elastic.co/kibana/kibana:8.12.1
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch
  minio:
    container_name: minio
    image: minio/minio
    attach: false
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_storage:/data
    environment:
      MINIO_ROOT_USER: bar
      MINIO_ROOT_PASSWORD: Strong#Pass#2022
    command: server --console-address ":9001" /data
  neo:
      container_name: neo4j
      attach: false
      image: neo4j:latest
      environment:
        - NEO4J_AUTH=none
      ports: 
        - 7474:7474
        - 7687:7687
      volumes:
        - neo4j_data:/data/
volumes:
  my_db:
  minio_storage:
  elasticsearch_vol:
  flink_checkpoints:
  neo4j_data: